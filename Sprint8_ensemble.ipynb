{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint アンサンブル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3種類のアンサンブル学習をスクラッチ実装していきます。そして、それぞれの効果を小さめのデータセットで確認します。\n",
    "\n",
    "ブレンディング\n",
    "\n",
    "バギング\n",
    "\n",
    "スタッキング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[: , [\"GrLivArea\" , \"YearBuilt\"]]\n",
    "y = df.loc[: , \"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "              X , y , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "lr = LinearRegression()\n",
    "svm = SVR()\n",
    "tree = DecisionTreeRegressor()\n",
    "forest = RandomForestClassifier()\n",
    "lgb = lgb.LGBMClassifier()\n",
    "xgb = xgb.XGBRegressor(colsample_bytree = 0.5, learning_rate =0.1, max_depth = 2, n_estimators = 50,subsample =  1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】ブレンディングのスクラッチ実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。\n",
    "\n",
    "精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。\n",
    "\n",
    "回帰では各モデルの平均値を最終的な出力とすることが一般的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_test , pred):\n",
    "    return mean_squared_error(y_test , pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "svm = SVR()\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "lr.fit(X_train , y_train)\n",
    "svm.fit(X_train , y_train)\n",
    "tree.fit(X_train , y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "pred_svm = svm.predict(X_test)\n",
    "pred_tree = tree.predict(X_test)\n",
    "\n",
    "\n",
    "mse_lr = MSE(y_test , pred_lr)\n",
    "mse_svm = MSE(y_test , pred_svm)\n",
    "mse_tree = MSE(y_test , pred_tree)\n",
    "# mse_mean = (mse_lr+mse_svm+mse_tree )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰のSME : 1381777484.71\n",
      "SVMのSME : 4624900550.36\n",
      "決定木のSME : 2281769631.37\n"
     ]
    }
   ],
   "source": [
    "print(\"線形回帰のSME : {:.2f}\".format(mse_lr))\n",
    "print(\"SVMのSME : {:.2f}\".format(mse_svm))\n",
    "print(\"決定木のSME : {:.2f}\".format(mse_tree))\n",
    "# print(\"平均SME : {:.2f}\".format(mse_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [lr, svm, tree]\n",
    "# model_names = [\"Linear Regression\", \"SVM\", \"Decision Tree\"]\n",
    "# def score(X_train , X_test , y_train , y_test):\n",
    "#     for model , name in zip(models, model_names):\n",
    "#         model.fit(X_train,y_train)\n",
    "#         print(name , model.score(X_test , y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・SVMのスコアが異常に悪い\n",
    "\n",
    "・前処理やハイパーパラメーターを変えて検証していく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重み（線形回帰、SVM、決定木）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "              X , y , test_size = 0.2)\n",
    "\n",
    "lr.fit(X_train , y_train)\n",
    "svm.fit(X_train , y_train)\n",
    "tree.fit(X_train , y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "pred_svm = svm.predict(X_test)\n",
    "pred_tree = tree.predict(X_test)\n",
    "\n",
    "pred_sum = pred_lr*0.5 + pred_svm*0.1 + pred_tree*0.4\n",
    "\n",
    "mse_lr = MSE(y_test , pred_lr)\n",
    "mse_svm = MSE(y_test , pred_svm)\n",
    "mse_tree = MSE(y_test , pred_tree)\n",
    "mse_mean = (mse_lr+mse_svm+mse_tree )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰のSME : 3164596808.71\n",
      "SVMのSME : 10190731994.87\n",
      "決定木のSME : 4745151314.36\n",
      "平均SME : 6033493372.65\n"
     ]
    }
   ],
   "source": [
    "print(\"線形回帰のSME : {:.2f}\".format(mse_lr))\n",
    "print(\"SVMのSME : {:.2f}\".format(mse_svm))\n",
    "print(\"決定木のSME : {:.2f}\".format(mse_tree))\n",
    "print(\"平均SME : {:.2f}\".format(mse_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重みを変えSMEが減少\n",
    "平均のSMEも減少した"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標準化（線形回帰、SVM、決定木）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "X_std = std.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "              X_std , y , test_size = 0.2)\n",
    "\n",
    "lr.fit(X_train , y_train)\n",
    "svm.fit(X_train , y_train)\n",
    "tree.fit(X_train , y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "pred_svm = svm.predict(X_test)\n",
    "pred_tree = tree.predict(X_test)\n",
    "\n",
    "pred_sum = pred_lr + pred_svm + pred_tree\n",
    "\n",
    "mse_lr = MSE(y_test , pred_lr)\n",
    "mse_svm = MSE(y_test , pred_svm)\n",
    "mse_tree = MSE(y_test , pred_tree)\n",
    "mse_mean = (mse_lr+mse_svm+mse_tree )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰のSME : 1892798287.93\n",
      "SVMのSME : 7549005683.31\n",
      "決定木のSME : 2278002319.77\n",
      "平均SME : 3906602097.00\n"
     ]
    }
   ],
   "source": [
    "print(\"線形回帰のSME : {:.2f}\".format(mse_lr))\n",
    "print(\"SVMのSME : {:.2f}\".format(mse_svm))\n",
    "print(\"決定木のSME : {:.2f}\".format(mse_tree))\n",
    "print(\"平均SME : {:.2f}\".format(mse_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "標準化によってもSMEが減少した"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを入れ替える（線形回帰、lgbm、決定木）\n",
    "\n",
    "SVMのスコアが悪いため、SVMとlgbmを入れ替えて実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "              X , y , test_size = 0.2)\n",
    "\n",
    "lr.fit(X_train , y_train)\n",
    "lgb.fit(X_train , y_train)\n",
    "tree.fit(X_train , y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "pred_lgb = lgb.predict(X_test)\n",
    "pred_tree = tree.predict(X_test)\n",
    "\n",
    "pred_sum = pred_lr + pred_lgb + pred_tree\n",
    "\n",
    "mse_lr = MSE(y_test , pred_lr)\n",
    "mse_lgb = MSE(y_test , pred_lgb)\n",
    "mse_tree = MSE(y_test , pred_tree)\n",
    "mse_mean = (mse_lr+mse_lgb+mse_tree )/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰のSME : 1967803547.34\n",
      "lgbのSME : 3204050894.29\n",
      "決定木のSME : 3140644437.73\n",
      "平均SME : 2770832959.79\n"
     ]
    }
   ],
   "source": [
    "print(\"線形回帰のSME : {:.2f}\".format(mse_lr))\n",
    "print(\"lgbのSME : {:.2f}\".format(mse_lgb))\n",
    "print(\"決定木のSME : {:.2f}\".format(mse_tree))\n",
    "print(\"平均SME : {:.2f}\".format(mse_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スコアが大幅に向上した\n",
    "平均値も一番優れていた"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試したこと\n",
    "・重みの初期値の変更\n",
    "・標準化\n",
    "・モデルの変更"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】バギングのスクラッチ実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バギングは入力データの選び方を多様化する方法です。\n",
    "\n",
    "学習データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ ブートストラップサンプル ）を作り出します。\n",
    "\n",
    "それらによってモデルをN個学習し、推定結果の平均をとります。\n",
    "\n",
    "ブレンディングと異なり、それぞれの重み付けを変えることはありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.loc[: , [\"GrLivArea\" , \"YearBuilt\"]]\n",
    "y = df.loc[: , \"SalePrice\"]\n",
    "# std = StandardScaler()\n",
    "# X_std = std.fit_transform(X)\n",
    "# X_std = pd.DataFrame(data = X_std)\n",
    "X_train , X_test ,y_train ,  y_test = train_test_split(\n",
    "             X , y , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = np.random.choice(X_train.index , X_train.shape[0] , replace=True)#.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 962,  797,  395, ..., 1329,   67,  809])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[X_t].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "sme_list = []\n",
    "def bagging(model , X , y , n = 10):\n",
    "    for i in range(n):\n",
    "        X_train , X_test ,y_train ,  y_test = train_test_split(\n",
    "             X , y , test_size = 0.2)\n",
    "        X_index = np.random.choice(X_train.index , X_train.shape[0] , replace=True)\n",
    "        X_train_n = X_train.loc[X_index]\n",
    "        model.fit(X_train_n , y_train)\n",
    "        pred = model.predict(X_test)\n",
    "        sme = mean_squared_error(y_test , pred)\n",
    "        sme_list.append(sme)\n",
    "#     print(\"スコア{}\".format(model.score(X_test , y_test)))\n",
    "    return (np.mean(sme_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4928511350.220617"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging(lr , X , y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3215618606.6417055"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4523739118.106428 - 7739357724.748134"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形回帰を用いて良い精度が確認できた"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】スタッキングのスクラッチ実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スタッキングの手順は以下の通りです。最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装してください。まずは \n",
    "K0 = 3\n",
    ",\n",
    "M0 = 2\n",
    " 程度にします。\n",
    "\n",
    "《学習時》\n",
    "\n",
    "（ステージ \n",
    "0\n",
    " ）\n",
    "\n",
    "学習データを \n",
    "K\n",
    "0\n",
    " 個に分割する。\n",
    "分割した内の \n",
    "(\n",
    "K\n",
    "0\n",
    "−\n",
    "1\n",
    ")\n",
    " 個をまとめて学習用データ、残り \n",
    "1\n",
    " 個を推定用データとする組み合わせが \n",
    "K\n",
    "0\n",
    " 個作れる。\n",
    "あるモデルのインスタンスを \n",
    "K\n",
    "0\n",
    " 個用意し、異なる学習用データを使い学習する。\n",
    "それぞれの学習済みモデルに対して、使っていない残り \n",
    "1\n",
    " 個の推定用データを入力し、推定値を得る。（これをブレンドデータと呼ぶ）\n",
    "さらに、異なるモデルのインスタンスも \n",
    "K\n",
    "0\n",
    " 個用意し、同様のことを行う。モデルが \n",
    "M\n",
    "0\n",
    " 個あれば、 \n",
    "M\n",
    "0\n",
    " 個のブレンドデータが得られる。\n",
    "（ステージ \n",
    "n\n",
    " ）\n",
    "\n",
    "ステージ \n",
    "n\n",
    "−\n",
    "1\n",
    " のブレンドデータを\n",
    "M\n",
    "n\n",
    "−\n",
    "1\n",
    " 次元の特徴量を持つ学習用データと考え、 \n",
    "K\n",
    "n\n",
    " 個に分割する。以下同様である。\n",
    "（ステージ \n",
    "N\n",
    " ）＊最後のステージ\n",
    "\n",
    "ステージ \n",
    "N\n",
    "−\n",
    "1\n",
    " の \n",
    "M\n",
    "N\n",
    "−\n",
    "1\n",
    " 個のブレンドデータを\n",
    "M\n",
    "N\n",
    "−\n",
    "1\n",
    " 次元の特徴量の入力として、1種類のモデルの学習を行う。これが最終的な推定を行うモデルとなる。\n",
    "《推定時》\n",
    "\n",
    "（ステージ \n",
    "0\n",
    " ）\n",
    "\n",
    "テストデータを \n",
    "K\n",
    "0\n",
    "×\n",
    "M\n",
    "0\n",
    " 個の学習済みモデルに入力し、\n",
    "K\n",
    "0\n",
    "×\n",
    "M\n",
    "0\n",
    " 個の推定値を得る。これを \n",
    "K\n",
    "0\n",
    " の軸で平均値を求め \n",
    "M\n",
    "0\n",
    " 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "（ステージ \n",
    "n\n",
    " ）\n",
    "\n",
    "ステージ \n",
    "n\n",
    "−\n",
    "1\n",
    " で得たブレンドテストを \n",
    "K\n",
    "n\n",
    "×\n",
    "M\n",
    "n\n",
    " 個の学習済みモデルに入力し、\n",
    "K\n",
    "n\n",
    "×\n",
    "M\n",
    "n\n",
    " 個の推定値を得る。これを \n",
    "K\n",
    "n\n",
    " の軸で平均値を求め \n",
    "M\n",
    "0\n",
    " 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "（ステージ \n",
    "N\n",
    " ）＊最後のステージ\n",
    "\n",
    "ステージ \n",
    "N\n",
    "−\n",
    "1\n",
    " で得たブレンドテストを学習済みモデルに入力し、推定値を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クロスバリデーション\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 読み込みに時間がかかるためGridSearchCVを実行するコードは必要時以外はコメントアウトにしておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters = {\"n_estimators\" : [50],\n",
    "#          \"learning_rate\":[0.1,0.3,0.5],\n",
    "#         \"max_depth\": [2,3,5,10],\n",
    "#          \"subsample\":[0.5,0.8,0.9,1],\n",
    "#          \"colsample_bytree\": [0.5,1.0],\n",
    "#          }\n",
    "\n",
    "# grid = GridSearchCV(estimator = xgb , param_grid = parameters , cv = kf , scoring = \"mean_squared_error\")\n",
    "# grid.fit(preds , y_train)\n",
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = { \"n_estimators\":[i for i in range(10,50,10)],\n",
    "#     \"criterion\":[\"gini\",\"entropy\"],\n",
    "#     \"max_depth\":[i for i in range(1,5,1)],\n",
    "#      'min_samples_split': [2, 4, 10,12,16],\n",
    "#     \"random_state\":[3],\n",
    "#          }\n",
    "\n",
    "# grid = GridSearchCV(estimator = forest , param_grid = parameters , cv = kf , scoring = \"mean_squared_error\")\n",
    "# grid.fit(preds , y_train)\n",
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid.best_score_)\n",
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.loc[: , [\"GrLivArea\" , \"YearBuilt\"]]\n",
    "y = df.loc[: , \"SalePrice\"]\n",
    "X_train , X_test ,y_train ,  y_test = train_test_split(\n",
    "             X , y , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クロスバリデーション\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = xgb.XGBRegressor(colsample_bytree = 0.5, learning_rate =0.1, max_depth = 2, n_estimators = 50,subsample =  1)\n",
    "forest = RandomForestClassifier(max_depth = 2, min_samples_split = 2, n_estimators = 40, random_state =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking(models , X_train ,X_test,y_train)\n",
    "X_std = std.fit_transform(X)\n",
    "X_std = pd.DataFrame(data = X_std)\n",
    "X_train , X_test ,y_train ,  y_test = train_test_split(\n",
    "             X_std , y , test_size = 0.2)\n",
    "#クロスバリデーション\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [xgb , lgb , lr]\n",
    "def Stacking(models , X_train , X_test , y_train):\n",
    "    preds = np.array([])\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "    kf = KFold(n_splits = 3 , random_state = 5)\n",
    "\n",
    "    #クロスバリデーションで学習、予測を行い、予測値とインデックスを保存\n",
    "    for m, model in enumerate(models):\n",
    "        for i , (tr_idx , va_idx) in enumerate(kf.split(X_train)):\n",
    "            tr_X , va_X = X_train.iloc[tr_idx] , X_train.iloc[va_idx]\n",
    "            tr_y , va_y = y_train.iloc[tr_idx] , y_train.iloc[va_idx]\n",
    "            model.fit(tr_X , tr_y) #va_X , va_y)\n",
    "            model.fit(va_X , va_y)\n",
    "            pred = model.predict(va_X)\n",
    "            preds = np.append(preds , pred)\n",
    "            pred_test = model.predict(X_test)\n",
    "            preds_test = np.append(preds_test , pred_test)\n",
    "            va_idxes.append(va_idx)\n",
    "    #バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n",
    "    preds = preds.reshape(1168 , len(models) )\n",
    "    preds_test = preds_test.reshape(292 , 9)\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    #preds = np.concatenate(preds , axis = 0)\n",
    "    order = np.argsort(va_idxes)\n",
    "#    pred_train = preds[order]\n",
    "    \n",
    "    #テストデータに対する予測値の平均をとる\n",
    "    preds_test_1 = np.mean(preds_test[: , :3] , axis = 1).reshape(-1,1)\n",
    "    preds_test_2 = np.mean(preds_test[: , 3:6] , axis = 1).reshape(-1,1)\n",
    "    preds_test_3 = np.mean(preds_test[: , 6:] , axis = 1).reshape(-1,1)\n",
    "    preds_test_sum = np.concatenate([preds_test_1 , preds_test_2 , preds_test_3] , axis=1)\n",
    "#     pred_train = pred_train.reshape(1168  , len(models))\n",
    "    return preds_test_sum , preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:35:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[02:35:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[02:35:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[02:35:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[02:35:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[02:35:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "preds_test , preds =Stacking(models , X_train ,X_test,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 3)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 3)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train , X_test , y_train , model):\n",
    "    model.fit(preds , y_train)\n",
    "    pred = model.predict(preds_test)\n",
    "    sme = mean_squared_error(y_test , pred)\n",
    "    return sme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5841546286.956702"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(preds , preds_test , y_train , lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル３、K-Fold3にて実施\n",
    "ステージ０にて線形回帰、XGB、lgb似て学習\n",
    "ステージNにて再度線形回帰を実施"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回のスクラッチを通してアンサンブル学習という技法を知り、引き出しが増えたと感じたがバリエーションの幅が広すぎて扱うのに苦労しそうな印象を感じた（パラメータチューニングなども入れると無限に組み合わせがある）\n",
    "しかし今回はグリッドサーチの復習にもなり機械学習の面白さの根源を知れてよかったと個人的に感じた"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
