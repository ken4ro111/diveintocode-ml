{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint ディープラーニングフレームワーク２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】公式Exampleを分担して実行\n",
    "\n",
    "TensorFLowの公式Exampleを分担して実行してください。\n",
    "\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。\n",
    "\n",
    "research\n",
    "\n",
    "定番のモデルから最新のモデルまで多様なコードが公開されています。\n",
    "https://github.com/tensorflow/models/tree/master/research\n",
    "\n",
    "tutorials\n",
    "\n",
    "TensorFLowのチュートリアルとして用意された簡単なモデルが含まれています。\n",
    "https://github.com/tensorflow/models/tree/master/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/research/object_detection\n",
    "\n",
    "Tensorflowオブジェクト検出API\n",
    "単一の画像で複数のオブジェクトをローカライズおよび識別することができる正確な機械学習モデルを作成することは、コンピュータービジョンの中心的な課題です。TensorFlow Object Detection APIは、TensorFlowの上に構築されたオープンソースフレームワークであり、オブジェクト検出モデルの構築、トレーニング、展開を容易にします。Googleでは、このコードベースがコンピュータービジョンのニーズに役立つことは確かであり、皆さんもそうなることを願っています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディープラーニングを用いて、1枚の画像を与え、何が写っているかを推定する技術を画像認識（Image Classification）といいます。\n",
    "\n",
    "一方で、物体検出（Object Detection）は画像のどこになにが写っているかを当てるという、より複雑な推定技術です。監視カメラの映像分析や顔認証システムなどにも応用されています。\n",
    "\n",
    "画像認識を行う際も大量の画像データが必要ですが、物体検出をするには、さらに検出したい物体の種類の数だけ必要な画像データが増えてしまいます。\n",
    "\n",
    "Tensorflow Object Detection APIでは学習済みのモデルが用意されており、80種類の物体を認識することができるため、気軽に物体検出を試すことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 物体検出の仕組み\n",
    "\n",
    "https://blogs.sas.com/content/sasjapan/2019/03/12/understanding-object-detection-in-deep-learning/\n",
    "物体検出に関する重要な問題の1つは、前景にある物体の数が画像によって様々に異なる、ということです。しかし、ここでは物体検出の仕組みを理解するために、まずは1つの画像に1個の物体しか存在しないと仮定し、この制約条件の下で物体検出問題を考えてみましょう。1つの画像に1個の物体しか存在しない場合、バウンディング・ボックスの発見と物体のカテゴリー判断という問題は、単純明快な方法で解決することができます。バウンディング・ボックスは4組の数値で表現されますから、バウンディング・ボックスの位置を学習するタスクは、回帰問題として無理なくモデル化することが可能です。そのタスクが済めば、物体のカテゴリー判断は分類問題として解くことができます。\n",
    "\n",
    "ここでの「制約条件付きの物体検出」という課題に関する回帰および分類問題に対する解法を提供するのは、図2に示す畳み込みニューラル・ネットワーク（CNN）です。コンピューター・ビジョンの領域における他の従来型タスク（例：画像認識、キーポイント検出、セマンティック・セグメンテーションなど）の場合と同様、ここでの「制約条件付きの物体検出」という課題では、固定数のターゲットを扱います。これらのターゲットの当てはめは、固定数の分類または回帰問題としてターゲットをモデル化することによって実行可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実装\n",
    "TensorFLowの公式Exampleを参考に実装してみたモデルは別ファイルにて送ります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】Iris（2値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data = iris.data , columns = iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "# df.loc[df['target'] == 0]\n",
    "# df.loc[df['target'] == 1]\n",
    "# df.loc[df['target'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[50: , :4].values\n",
    "y = df.iloc[50: , -1].values\n",
    "y[y==2]=0\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(\n",
    "               X , y , test_size = 0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "               X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D , MaxPooling2D , Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 1s 18ms/step - loss: 0.6316 - accuracy: 0.5938\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7031\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7188\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.8125\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8750\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7812\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.8281\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.8438\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8906\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.9219\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8594\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.9531\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3825 - accuracy: 0.9219\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.9062\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.9375\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.9375\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.9062\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.9844\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.9375\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.9531\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.9219\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.9062\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.9688\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3077 - accuracy: 0.9375\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3002 - accuracy: 0.9844\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.9375\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2930 - accuracy: 0.9844\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.9688\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.9375\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.9688\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.9688\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.9375\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2613 - accuracy: 0.9531\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2669 - accuracy: 0.9531\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9844\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2546 - accuracy: 0.9844\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.9688\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2603 - accuracy: 0.9844\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.9531\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9688\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2387 - accuracy: 0.9375\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2349 - accuracy: 0.9844\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2273 - accuracy: 0.9844\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9844\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9844\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9844\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.9844\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2133 - accuracy: 0.9844\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9844\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2247 - accuracy: 0.9844\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2053 - accuracy: 0.9844\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2008 - accuracy: 0.9844\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9844\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2039 - accuracy: 0.9688\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.9844\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9688\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9844\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.1875 - accuracy: 0.9844\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9844\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.1835 - accuracy: 0.9844\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9844\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9844\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1832 - accuracy: 0.9844\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1825 - accuracy: 0.9844\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9844\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9844\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9844\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9844\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1701 - accuracy: 0.9844\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9688\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1738 - accuracy: 0.9844\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9844\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1622 - accuracy: 0.9688\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9844\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9688\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9844\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9844\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1639 - accuracy: 0.9844\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1483 - accuracy: 0.9844\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9844\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1546 - accuracy: 0.9844\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9844\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9844\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1506 - accuracy: 0.9844\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9844\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9844\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9844\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9844\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1415 - accuracy: 0.9844\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9844\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1454 - accuracy: 0.9844\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9844\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.9844\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.9688\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9844\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1401 - accuracy: 0.9844\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 0.9844\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session( )\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1 , input_shape = (4 , )))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\" , \n",
    "             optimizer = Adam(lr = 0.01) , \n",
    "             metrics = [\"accuracy\"])\n",
    "history = model.fit(X_train , y_train , \n",
    "                   batch_size = 1 , \n",
    "                   epochs = 100 , \n",
    "                   verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session( )\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape = (4 , ))\n",
    "x = tf.keras.layers.Dense(10 , activation = tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(10 , activation = tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Dense(10 , activation = tf.nn.relu)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1 , activation = tf.nn.sigmoid)(x)\n",
    "model = tf.keras.Model(inputs = input_data , outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 281\n",
      "Trainable params: 281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 1s 16ms/sample - loss: 0.6725 - acc: 0.6406\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6620 - acc: 0.5625\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 0s 978us/sample - loss: 0.6505 - acc: 0.5469\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.6472 - acc: 0.5156\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.5605 - acc: 0.6719\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.5132 - acc: 0.7188\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 0s 791us/sample - loss: 0.5264 - acc: 0.6875\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 0s 837us/sample - loss: 0.5255 - acc: 0.7188\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3096 - acc: 0.9531\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.2346 - acc: 0.9375\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss = \"binary_crossentropy\" , \n",
    "             optimizer = tf.train.AdamOptimizer(learning_rate = 0.01) , \n",
    "             metrics = [\"accuracy\"])\n",
    "history = model.fit(X_train , y_train , \n",
    "                   batch_size=5 , \n",
    "                   epochs = 10 , \n",
    "                   verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_proba [0.77170587 0.08704585 0.96766686 0.8604611  0.0473223  0.10444227\n",
      " 0.9657655  0.0562548  0.13960212 0.17691141 0.36097068 0.7205821\n",
      " 0.8938831  0.8785064  0.30036366 0.1058782 ]\n",
      "y_pred [1 0 1 1 0 0 1 0 0 0 0 1 1 1 0 0]\n",
      "精度 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_pred_proba = model.predict(X_val)[: , 0]\n",
    "\n",
    "y_pred = np.where(y_pred_proba > 0.5 , 1 , 0)\n",
    "print(\"y_pred_proba\" , y_pred_proba)\n",
    "print(\"y_pred\" , y_pred)\n",
    "print(\"精度\" , precision_score(y_val , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】Iris（多値分類）をKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = iris.data , columns = iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "X = df.iloc[: , :4].values\n",
    "y = df.iloc[: , -1].values\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y = enc.fit_transform(y[:, np.newaxis])\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(\n",
    "               X , y , test_size = 0.2)\n",
    "X_train , X_val , y_train , y_val = train_test_split(\n",
    "                X_train , y_train , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session( )\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(4 , ))\n",
    "x = tf.keras.layers.Dense(10 , activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(10 , activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Dense(10 , activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(3 , activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs = input_data , outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 303\n",
      "Trainable params: 303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 1s 12ms/sample - loss: 0.7841 - acc: 0.5417\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.3697 - acc: 0.8542\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.2988 - acc: 0.9062\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.3181 - acc: 0.8750\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2139 - acc: 0.9375\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.2104 - acc: 0.9167\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2500 - acc: 0.9271\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.2702 - acc: 0.9271\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1589 - acc: 0.9271\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1945 - acc: 0.9062\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\" , \n",
    "             optimizer = tf.train.AdamOptimizer(learning_rate=0.01) , \n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train , y_train , \n",
    "                   batch_size = 1 , \n",
    "                   epochs = 10 , \n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         8\n",
      "\n",
      "avg / total       1.00      1.00      1.00        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred_proba = model.predict(X_val)\n",
    "y_pred = np.where(y_pred_proba > 0.5 , 1 , 0)\n",
    "print(classification_report(y_val , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "96/96 [==============================] - 1s 15ms/sample - loss: 1.0984 - acc: 0.3854\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.8264 - acc: 0.5938\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.6737 - acc: 0.6667\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.6324 - acc: 0.6667\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.5654 - acc: 0.7188\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.5154 - acc: 0.8229\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.4729 - acc: 0.8021\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.5096 - acc: 0.7708\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.4377 - acc: 0.8229\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.4321 - acc: 0.8438\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.4702 - acc: 0.8021\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.3857 - acc: 0.8125\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.3055 - acc: 0.9271\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2950 - acc: 0.9062\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.2961 - acc: 0.8854\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2550 - acc: 0.9062\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.2190 - acc: 0.9479\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2435 - acc: 0.9375\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.2069 - acc: 0.9167\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2136 - acc: 0.9167\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.2061 - acc: 0.9062\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1774 - acc: 0.9479\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.2324 - acc: 0.9062\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2023 - acc: 0.9167\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1573 - acc: 0.9583\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1854 - acc: 0.9062\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1505 - acc: 0.9479\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1798 - acc: 0.9271\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 5ms/sample - loss: 0.1902 - acc: 0.9062\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1603 - acc: 0.9271\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1221 - acc: 0.9479\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1294 - acc: 0.9479\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1278 - acc: 0.9375\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1255 - acc: 0.9583\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1100 - acc: 0.9688\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1196 - acc: 0.9375\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1279 - acc: 0.9479\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1994 - acc: 0.9167\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1289 - acc: 0.9479\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1277 - acc: 0.9688\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2240 - acc: 0.9271\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1250 - acc: 0.9479\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1037 - acc: 0.9479\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1273 - acc: 0.9479\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 0s 5ms/sample - loss: 0.1001 - acc: 0.9583\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2101 - acc: 0.9167\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1364 - acc: 0.9583\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0976 - acc: 0.9479\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1312 - acc: 0.9375\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0930 - acc: 0.9583\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 1s 5ms/sample - loss: 0.1582 - acc: 0.9271\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1084 - acc: 0.9583\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 0s 5ms/sample - loss: 0.1270 - acc: 0.9271\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1135 - acc: 0.9583\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 0s 5ms/sample - loss: 0.0925 - acc: 0.9583\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1491 - acc: 0.9479\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1171 - acc: 0.9583\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0766 - acc: 0.9792\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1343 - acc: 0.9479\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0871 - acc: 0.9688\n",
      "Epoch 61/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0851 - acc: 0.9688\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1471 - acc: 0.9167\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1465 - acc: 0.9375\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1390 - acc: 0.9375\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 0s 5ms/sample - loss: 0.0894 - acc: 0.9792\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1043 - acc: 0.9583\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.0787 - acc: 0.9688\n",
      "Epoch 68/100\n",
      "96/96 [==============================] - 0s 5ms/sample - loss: 0.1439 - acc: 0.9375 0s - loss: 0.1425 - acc: 0.934\n",
      "Epoch 69/100\n",
      "96/96 [==============================] - 0s 5ms/sample - loss: 0.1072 - acc: 0.9479\n",
      "Epoch 70/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1939 - acc: 0.9479\n",
      "Epoch 71/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1182 - acc: 0.9479\n",
      "Epoch 72/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.0750 - acc: 0.9688\n",
      "Epoch 73/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0605 - acc: 0.9792\n",
      "Epoch 74/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2070 - acc: 0.9167\n",
      "Epoch 75/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0917 - acc: 0.9479\n",
      "Epoch 76/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0796 - acc: 0.9792\n",
      "Epoch 77/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1381 - acc: 0.9375\n",
      "Epoch 78/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1736 - acc: 0.9375\n",
      "Epoch 79/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0716 - acc: 0.9583\n",
      "Epoch 80/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.0961 - acc: 0.9583\n",
      "Epoch 81/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1113 - acc: 0.9479\n",
      "Epoch 82/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1001 - acc: 0.9479\n",
      "Epoch 83/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1066 - acc: 0.9583\n",
      "Epoch 84/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1324 - acc: 0.9479\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1150 - acc: 0.9688\n",
      "Epoch 86/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0968 - acc: 0.9688\n",
      "Epoch 87/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0890 - acc: 0.9688\n",
      "Epoch 88/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0850 - acc: 0.9688\n",
      "Epoch 89/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1177 - acc: 0.9583\n",
      "Epoch 90/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1258 - acc: 0.9479\n",
      "Epoch 91/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1053 - acc: 0.9792\n",
      "Epoch 92/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1156 - acc: 0.9375\n",
      "Epoch 93/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1043 - acc: 0.9583\n",
      "Epoch 94/100\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1232 - acc: 0.9479\n",
      "Epoch 95/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1472 - acc: 0.9271\n",
      "Epoch 96/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1014 - acc: 0.9583\n",
      "Epoch 97/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1330 - acc: 0.9271\n",
      "Epoch 98/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0874 - acc: 0.9583\n",
      "Epoch 99/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0661 - acc: 0.9896\n",
      "Epoch 100/100\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1150 - acc: 0.9688\n"
     ]
    }
   ],
   "source": [
    "K.clear_session( )\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.relu , input_shape=(4 , )))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.relu ))\n",
    "model.add(tf.keras.layers.Dense(3 , activation = tf.nn.softmax))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\" , \n",
    "             optimizer = tf.train.AdamOptimizer(learning_rate=0.01) , \n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train , y_train , \n",
    "                   batch_size = 1 , \n",
    "                   epochs = 100 , \n",
    "                   verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】House PricesをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.loc[: , [\"GrLivArea\" , \"YearBuilt\"]]\n",
    "y = df.loc[: , \"SalePrice\"]\n",
    "y = np.log(y)\n",
    "X_train , X_test , y_train , y_test = train_test_split(\n",
    "                X , y , test_size=0.2)\n",
    "X_train , X_val , y_train , y_val = train_test_split(\n",
    "                X_train , y_train , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session( )\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape= (2 , ))\n",
    "x = tf.keras.layers.Dense(10 , activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(10 , activation=tf.nn.relu)(x)\n",
    "y1 = tf.keras.layers.Dense(10 , activation=tf.nn.relu)(x)\n",
    "y2 = tf.keras.layers.Dense(10 , activation=tf.nn.relu)(y1)\n",
    "z = tf.keras.layers.concatenate([y1 , y2])\n",
    "output = tf.keras.layers.Dense(1 ,)(z)#回帰分析のため出力前は活性化関数は指定しない\n",
    "model = tf.keras.Model(inputs = input_data , outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           30          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           110         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           110         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           110         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20)           0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            21          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 381\n",
      "Trainable params: 381\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hayashikentaro/.pyenv/versions/anaconda3-5.3.1/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"mean_squared_error\" , \n",
    "             optimizer = tf.train.AdamOptimizer(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 934 samples\n",
      "Epoch 1/10\n",
      "934/934 [==============================] - 5s 6ms/sample - loss: 247.5006 - val_loss: 0.1540\n",
      "Epoch 2/10\n",
      "934/934 [==============================] - 5s 5ms/sample - loss: 0.7621 - val_loss: 0.1347\n",
      "Epoch 3/10\n",
      "934/934 [==============================] - 4s 5ms/sample - loss: 1.7008 - val_loss: 3.7192\n",
      "Epoch 4/10\n",
      "934/934 [==============================] - 6s 6ms/sample - loss: 3.1108 - val_loss: 1.9301\n",
      "Epoch 5/10\n",
      "934/934 [==============================] - 4s 4ms/sample - loss: 2.2103 - val_loss: 0.4674\n",
      "Epoch 6/10\n",
      "934/934 [==============================] - 4s 4ms/sample - loss: 1.1076 - val_loss: 0.0560\n",
      "Epoch 7/10\n",
      "934/934 [==============================] - 5s 5ms/sample - loss: 0.0894 - val_loss: 0.0525\n",
      "Epoch 8/10\n",
      "934/934 [==============================] - 4s 5ms/sample - loss: 0.1277 - val_loss: 0.0572\n",
      "Epoch 9/10\n",
      "934/934 [==============================] - 4s 4ms/sample - loss: 0.1586 - val_loss: 0.0628\n",
      "Epoch 10/10\n",
      "934/934 [==============================] - 5s 5ms/sample - loss: 0.1790 - val_loss: 0.1327\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train , y_train , \n",
    "                   batch_size = 1 , \n",
    "                   epochs = 10 , \n",
    "                   verbose = 1 , \n",
    "                   validation_data = (X_train , y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 934 samples\n",
      "Epoch 1/10\n",
      "934/934 [==============================] - 6s 6ms/sample - loss: 51.2304 - val_loss: 0.2193\n",
      "Epoch 2/10\n",
      "934/934 [==============================] - 7s 7ms/sample - loss: 0.9053 - val_loss: 0.2097\n",
      "Epoch 3/10\n",
      "934/934 [==============================] - 4s 4ms/sample - loss: 4.6344 - val_loss: 0.4354\n",
      "Epoch 4/10\n",
      "934/934 [==============================] - 3s 4ms/sample - loss: 0.4936 - val_loss: 0.2193\n",
      "Epoch 5/10\n",
      "934/934 [==============================] - 4s 4ms/sample - loss: 1.2368 - val_loss: 0.3119\n",
      "Epoch 6/10\n",
      "934/934 [==============================] - 3s 4ms/sample - loss: 0.9670 - val_loss: 0.2162\n",
      "Epoch 7/10\n",
      "934/934 [==============================] - 3s 4ms/sample - loss: 0.7045 - val_loss: 0.6193\n",
      "Epoch 8/10\n",
      "934/934 [==============================] - 3s 3ms/sample - loss: 0.7842 - val_loss: 0.1177\n",
      "Epoch 9/10\n",
      "934/934 [==============================] - 3s 4ms/sample - loss: 0.3193 - val_loss: 0.1448\n",
      "Epoch 10/10\n",
      "934/934 [==============================] - 4s 5ms/sample - loss: 0.2350 - val_loss: 0.0503\n"
     ]
    }
   ],
   "source": [
    "K.clear_session( )\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.relu , input_shape = (2 , )))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1 , ))\n",
    "\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\" , \n",
    "             optimizer = tf.train.AdamOptimizer(learning_rate=0.01))\n",
    "\n",
    "history = model.fit(X_train , y_train , \n",
    "                   batch_size = 1 , \n",
    "                   epochs = 10 , \n",
    "                   verbose = 1 , \n",
    "                   validation_data = (X_train , y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history[\"loss\"])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】MNISTをKerasで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1 , 784)\n",
    "X_test = X_test.reshape(-1 , 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# y_train = tf.one_hot(y_train , depth=3 ,dtype=None)\n",
    "# y_test = tf.one_hot(y_test , depth=3 , dtype=None)\n",
    "X_train = X_train.reshape(-1 , 28 , 28 , 1)\n",
    "X_test = X_test.reshape(-1 , 28 , 28 , 1)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session( )\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(28 , 28 , 1))\n",
    "con1 = tf.keras.layers.Conv2D(3 , kernel_size = (2,2)  , activation = tf.nn.relu)(input_data)\n",
    "max_p1 = tf.keras.layers.MaxPooling2D((3,3) , strides=(1,1))(con1)\n",
    "con2 = tf.keras.layers.Conv2D(3 , (2,2) , activation = tf.nn.relu)(max_p1)\n",
    "max_p2 = tf.keras.layers.MaxPooling2D((3,3) , strides = (2,2))(con2)\n",
    "fla = tf.keras.layers.Flatten()(max_p2)\n",
    "x = tf.keras.layers.Dense(100 , activation=tf.nn.relu)(fla)\n",
    "x = tf.keras.layers.Dense(50 , activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Dense(20 , activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(10 , activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs = input_data , outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 27, 27, 3)         15        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 25, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 3)         39        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 363)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               36400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 42,734\n",
      "Trainable params: 42,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 63s 1ms/sample - loss: 0.3337 - acc: 0.8951\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 57s 1ms/sample - loss: 0.1248 - acc: 0.9631\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 56s 1ms/sample - loss: 0.0973 - acc: 0.9708\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 59s 1ms/sample - loss: 0.0848 - acc: 0.9745\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 59s 1ms/sample - loss: 0.0817 - acc: 0.9758\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 55s 1ms/sample - loss: 0.0680 - acc: 0.9791\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 58s 1ms/sample - loss: 0.0641 - acc: 0.9813\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 62s 1ms/sample - loss: 0.0600 - acc: 0.9821\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 61s 1ms/sample - loss: 0.0651 - acc: 0.9806\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 62s 1ms/sample - loss: 0.0580 - acc: 0.9834\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\" , \n",
    "             optimizer = tf.train.AdamOptimizer(learning_rate=0.01) , \n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train , y_train , \n",
    "                   batch_size = 100 , \n",
    "                   epochs = 10 , \n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】（アドバンス課題）PyTorchへの書き換え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
